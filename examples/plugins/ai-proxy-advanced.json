{
  "fields": [
    {
      "balancer": {
        "fields": [
          {
            "algorithm": {
              "default": "round-robin",
              "description": "Which load balancing algorithm to use.",
              "one_of": [
                "consistent-hashing",
                "lowest-latency",
                "lowest-usage",
                "priority",
                "round-robin",
                "semantic"
              ],
              "type": "string"
            }
          },
          {
            "connect_timeout": {
              "between": [
                1,
                2147483646
              ],
              "default": 60000,
              "type": "integer"
            }
          },
          {
            "failover_criteria": {
              "default": [
                "error",
                "timeout"
              ],
              "description": "Specifies in which cases an upstream response should be failover to the next target. Each option in the array is equivalent to the function of http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_next_upstream",
              "elements": {
                "one_of": [
                  "error",
                  "http_403",
                  "http_404",
                  "http_429",
                  "http_500",
                  "http_502",
                  "http_503",
                  "http_504",
                  "invalid_header",
                  "non_idempotent",
                  "timeout"
                ],
                "type": "string"
              },
              "type": "array"
            }
          },
          {
            "hash_on_header": {
              "default": "X-Kong-LLM-Request-ID",
              "description": "The header to use for consistent-hashing.",
              "type": "string"
            }
          },
          {
            "latency_strategy": {
              "default": "tpot",
              "description": "What metrics to use for latency. Available values are: `tpot` (time-per-output-token) and `e2e`.",
              "one_of": [
                "e2e",
                "tpot"
              ],
              "type": "string"
            }
          },
          {
            "read_timeout": {
              "between": [
                1,
                2147483646
              ],
              "default": 60000,
              "type": "integer"
            }
          },
          {
            "retries": {
              "between": [
                0,
                32767
              ],
              "default": 5,
              "description": "The number of retries to execute upon failure to proxy.",
              "type": "integer"
            }
          },
          {
            "slots": {
              "between": [
                10,
                65536
              ],
              "default": 10000,
              "description": "The number of slots in the load balancer algorithm.",
              "type": "integer"
            }
          },
          {
            "tokens_count_strategy": {
              "default": "total-tokens",
              "description": "What tokens to use for usage calculation. Available values are: `total_tokens` `prompt_tokens`, `completion_tokens` and `cost`.",
              "one_of": [
                "completion-tokens",
                "cost",
                "prompt-tokens",
                "total-tokens"
              ],
              "type": "string"
            }
          },
          {
            "write_timeout": {
              "between": [
                1,
                2147483646
              ],
              "default": 60000,
              "type": "integer"
            }
          }
        ],
        "required": true,
        "type": "record"
      }
    },
    {
      "embeddings": {
        "entity_checks": [
          {
            "conditional_at_least_one_of": {
              "if_field": "model.provider",
              "if_match": {
                "one_of": [
                  "azure"
                ]
              },
              "then_at_least_one_of": [
                "model.options.azure.instance"
              ],
              "then_err": "must set %s for azure provider"
            }
          },
          {
            "conditional_at_least_one_of": {
              "if_field": "model.provider",
              "if_match": {
                "one_of": [
                  "azure"
                ]
              },
              "then_at_least_one_of": [
                "model.options.azure.api_version"
              ],
              "then_err": "must set %s for azure provider"
            }
          },
          {
            "conditional_at_least_one_of": {
              "if_field": "model.provider",
              "if_match": {
                "one_of": [
                  "azure"
                ]
              },
              "then_at_least_one_of": [
                "model.options.azure.deployment_id"
              ],
              "then_err": "must set %s for azure provider"
            }
          }
        ],
        "fields": [
          {
            "auth": {
              "fields": [
                {
                  "allow_override": {
                    "default": false,
                    "description": "If enabled, the authorization header or parameter can be overridden in the request by the value configured in the plugin.",
                    "required": false,
                    "type": "boolean"
                  }
                },
                {
                  "aws_access_key_id": {
                    "description": "Set this if you are using an AWS provider (Bedrock) and you are authenticating using static IAM User credentials. Setting this will override the AWS_ACCESS_KEY_ID environment variable for this plugin instance.",
                    "encrypted": true,
                    "referenceable": true,
                    "required": false,
                    "type": "string"
                  }
                },
                {
                  "aws_secret_access_key": {
                    "description": "Set this if you are using an AWS provider (Bedrock) and you are authenticating using static IAM User credentials. Setting this will override the AWS_SECRET_ACCESS_KEY environment variable for this plugin instance.",
                    "encrypted": true,
                    "referenceable": true,
                    "required": false,
                    "type": "string"
                  }
                },
                {
                  "azure_client_id": {
                    "description": "If azure_use_managed_identity is set to true, and you need to use a different user-assigned identity for this LLM instance, set the client ID.",
                    "referenceable": true,
                    "required": false,
                    "type": "string"
                  }
                },
                {
                  "azure_client_secret": {
                    "description": "If azure_use_managed_identity is set to true, and you need to use a different user-assigned identity for this LLM instance, set the client secret.",
                    "encrypted": true,
                    "referenceable": true,
                    "required": false,
                    "type": "string"
                  }
                },
                {
                  "azure_tenant_id": {
                    "description": "If azure_use_managed_identity is set to true, and you need to use a different user-assigned identity for this LLM instance, set the tenant ID.",
                    "referenceable": true,
                    "required": false,
                    "type": "string"
                  }
                },
                {
                  "azure_use_managed_identity": {
                    "default": false,
                    "description": "Set true to use the Azure Cloud Managed Identity (or user-assigned identity) to authenticate with Azure-provider models.",
                    "required": false,
                    "type": "boolean"
                  }
                },
                {
                  "gcp_service_account_json": {
                    "description": "Set this field to the full JSON of the GCP service account to authenticate, if required. If null (and gcp_use_service_account is true), Kong will attempt to read from environment variable `GCP_SERVICE_ACCOUNT`.",
                    "encrypted": true,
                    "referenceable": true,
                    "required": false,
                    "type": "string"
                  }
                },
                {
                  "gcp_use_service_account": {
                    "default": false,
                    "description": "Use service account auth for GCP-based providers and models.",
                    "required": false,
                    "type": "boolean"
                  }
                },
                {
                  "header_name": {
                    "description": "If AI model requires authentication via Authorization or API key header, specify its name here.",
                    "referenceable": true,
                    "required": false,
                    "type": "string"
                  }
                },
                {
                  "header_value": {
                    "description": "Specify the full auth header value for 'header_name', for example 'Bearer key' or just 'key'.",
                    "encrypted": true,
                    "referenceable": true,
                    "required": false,
                    "type": "string"
                  }
                },
                {
                  "param_location": {
                    "description": "Specify whether the 'param_name' and 'param_value' options go in a query string, or the POST form/JSON body.",
                    "one_of": [
                      "body",
                      "query"
                    ],
                    "required": false,
                    "type": "string"
                  }
                },
                {
                  "param_name": {
                    "description": "If AI model requires authentication via query parameter, specify its name here.",
                    "referenceable": true,
                    "required": false,
                    "type": "string"
                  }
                },
                {
                  "param_value": {
                    "description": "Specify the full parameter value for 'param_name'.",
                    "encrypted": true,
                    "referenceable": true,
                    "required": false,
                    "type": "string"
                  }
                }
              ],
              "required": false,
              "type": "record"
            }
          },
          {
            "model": {
              "fields": [
                {
                  "name": {
                    "description": "Model name to execute.",
                    "required": true,
                    "type": "string"
                  }
                },
                {
                  "options": {
                    "description": "Key/value settings for the model",
                    "fields": [
                      {
                        "azure": {
                          "fields": [
                            {
                              "api_version": {
                                "default": "2023-05-15",
                                "description": "'api-version' for Azure OpenAI instances.",
                                "required": false,
                                "type": "string"
                              }
                            },
                            {
                              "deployment_id": {
                                "description": "Deployment ID for Azure OpenAI instances.",
                                "required": false,
                                "type": "string"
                              }
                            },
                            {
                              "instance": {
                                "description": "Instance name for Azure OpenAI hosted models.",
                                "required": false,
                                "type": "string"
                              }
                            }
                          ],
                          "required": true,
                          "type": "record"
                        }
                      },
                      {
                        "bedrock": {
                          "entity_checks": [
                            {
                              "mutually_required": [
                                "aws_assume_role_arn",
                                "aws_role_session_name"
                              ]
                            }
                          ],
                          "fields": [
                            {
                              "aws_assume_role_arn": {
                                "description": "If using AWS providers (Bedrock) you can assume a different role after authentication with the current IAM context is successful.",
                                "required": false,
                                "type": "string"
                              }
                            },
                            {
                              "aws_region": {
                                "description": "If using AWS providers (Bedrock) you can override the `AWS_REGION` environment variable by setting this option.",
                                "required": false,
                                "type": "string"
                              }
                            },
                            {
                              "aws_role_session_name": {
                                "description": "If using AWS providers (Bedrock), set the identifier of the assumed role session.",
                                "type": "string"
                              }
                            },
                            {
                              "aws_sts_endpoint_url": {
                                "description": "If using AWS providers (Bedrock), override the STS endpoint URL when assuming a different role.",
                                "type": "string"
                              }
                            },
                            {
                              "embeddings_normalize": {
                                "default": false,
                                "description": "If using AWS providers (Bedrock), set to true to normalize the embeddings.",
                                "type": "boolean"
                              }
                            },
                            {
                              "performance_config_latency": {
                                "description": "Force the client's performance configuration 'latency' for all requests. Leave empty to let the consumer select the performance configuration.",
                                "required": false,
                                "type": "string"
                              }
                            }
                          ],
                          "required": false,
                          "type": "record"
                        }
                      },
                      {
                        "gemini": {
                          "entity_checks": [
                            {
                              "mutually_required": [
                                "api_endpoint",
                                "location_id",
                                "project_id"
                              ]
                            }
                          ],
                          "fields": [
                            {
                              "api_endpoint": {
                                "description": "If running Gemini on Vertex, specify the regional API endpoint (hostname only).",
                                "required": false,
                                "type": "string"
                              }
                            },
                            {
                              "location_id": {
                                "description": "If running Gemini on Vertex, specify the location ID.",
                                "required": false,
                                "type": "string"
                              }
                            },
                            {
                              "project_id": {
                                "description": "If running Gemini on Vertex, specify the project ID.",
                                "required": false,
                                "type": "string"
                              }
                            }
                          ],
                          "required": false,
                          "type": "record"
                        }
                      },
                      {
                        "huggingface": {
                          "fields": [
                            {
                              "use_cache": {
                                "description": "Use the cache layer on the inference API",
                                "required": false,
                                "type": "boolean"
                              }
                            },
                            {
                              "wait_for_model": {
                                "description": "Wait for the model if it is not ready",
                                "required": false,
                                "type": "boolean"
                              }
                            }
                          ],
                          "required": false,
                          "type": "record"
                        }
                      },
                      {
                        "upstream_url": {
                          "description": "upstream url for the embeddings",
                          "required": false,
                          "type": "string"
                        }
                      }
                    ],
                    "required": false,
                    "type": "record"
                  }
                },
                {
                  "provider": {
                    "description": "AI provider format to use for embeddings API",
                    "one_of": [
                      "azure",
                      "bedrock",
                      "gemini",
                      "huggingface",
                      "mistral",
                      "openai"
                    ],
                    "required": true,
                    "type": "string"
                  }
                }
              ],
              "required": true,
              "type": "record"
            }
          }
        ],
        "required": false,
        "type": "record"
      }
    },
    {
      "genai_category": {
        "default": "text/generation",
        "description": "Generative AI category of the request",
        "one_of": [
          "audio/speech",
          "audio/transcription",
          "image/generation",
          "realtime/generation",
          "text/embeddings",
          "text/generation",
          "video/generation"
        ],
        "required": false,
        "type": "string"
      }
    },
    {
      "llm_format": {
        "default": "openai",
        "description": "LLM input and output format and schema to use",
        "one_of": [
          "bedrock",
          "cohere",
          "gemini",
          "huggingface",
          "openai"
        ],
        "required": false,
        "type": "string"
      }
    },
    {
      "max_request_body_size": {
        "default": 8192,
        "description": "max allowed body size allowed to be introspected. 0 means unlimited, but the size of this body will still be limited by Nginx's client_max_body_size.",
        "gt": 0,
        "type": "integer"
      }
    },
    {
      "model_name_header": {
        "default": true,
        "description": "Display the model name selected in the X-Kong-LLM-Model response header",
        "type": "boolean"
      }
    },
    {
      "response_streaming": {
        "default": "allow",
        "description": "Whether to 'optionally allow', 'deny', or 'always' (force) the streaming of answers via server sent events.",
        "one_of": [
          "allow",
          "always",
          "deny"
        ],
        "required": false,
        "type": "string"
      }
    },
    {
      "targets": {
        "elements": {
          "entity_checks": [
            {
              "conditional": {
                "if_field": "model.provider",
                "if_match": {
                  "one_of": [
                    "bedrock",
                    "gemini"
                  ]
                },
                "then_err": "bedrock and gemini only support auth.allow_override = false",
                "then_field": "auth.allow_override",
                "then_match": {
                  "eq": false
                }
              }
            },
            {
              "conditional_at_least_one_of": {
                "if_field": "model.provider",
                "if_match": {
                  "one_of": [
                    "llama2"
                  ]
                },
                "then_at_least_one_of": [
                  "model.options.llama2_format"
                ],
                "then_err": "must set %s for llama2 provider"
              }
            },
            {
              "conditional_at_least_one_of": {
                "if_field": "model.provider",
                "if_match": {
                  "one_of": [
                    "mistral"
                  ]
                },
                "then_at_least_one_of": [
                  "model.options.mistral_format"
                ],
                "then_err": "must set %s for mistral provider"
              }
            },
            {
              "conditional_at_least_one_of": {
                "if_field": "model.provider",
                "if_match": {
                  "one_of": [
                    "anthropic"
                  ]
                },
                "then_at_least_one_of": [
                  "model.options.anthropic_version"
                ],
                "then_err": "must set %s for anthropic provider"
              }
            },
            {
              "conditional_at_least_one_of": {
                "if_field": "model.provider",
                "if_match": {
                  "one_of": [
                    "azure"
                  ]
                },
                "then_at_least_one_of": [
                  "model.options.azure_instance"
                ],
                "then_err": "must set %s for azure provider"
              }
            },
            {
              "conditional_at_least_one_of": {
                "if_field": "model.provider",
                "if_match": {
                  "one_of": [
                    "azure"
                  ]
                },
                "then_at_least_one_of": [
                  "model.options.azure_api_version"
                ],
                "then_err": "must set %s for azure provider"
              }
            },
            {
              "conditional_at_least_one_of": {
                "if_field": "model.provider",
                "if_match": {
                  "one_of": [
                    "azure"
                  ]
                },
                "then_at_least_one_of": [
                  "model.options.azure_deployment_id"
                ],
                "then_err": "must set %s for azure provider"
              }
            },
            {
              "conditional_at_least_one_of": {
                "if_field": "model.provider",
                "if_match": {
                  "one_of": [
                    "llama2"
                  ]
                },
                "then_at_least_one_of": [
                  "model.options.upstream_url"
                ],
                "then_err": "must set %s for self-hosted providers/models"
              }
            },
            {
              "custom_entity_check": {
                "field_sources": [
                  "logging",
                  "model",
                  "route_type"
                ]
              }
            },
            {
              "custom_entity_check": {
                "field_sources": [
                  "route_type"
                ]
              }
            },
            {
              "custom_entity_check": {
                "field_sources": [
                  "model",
                  "route_type"
                ]
              }
            },
            {
              "custom_entity_check": {
                "field_sources": [
                  "model",
                  "route_type"
                ]
              }
            },
            {
              "mutually_required": [
                "auth.header_name",
                "auth.header_value"
              ]
            },
            {
              "mutually_required": [
                "auth.param_location",
                "auth.param_name",
                "auth.param_value"
              ]
            }
          ],
          "fields": [
            {
              "auth": {
                "fields": [
                  {
                    "allow_override": {
                      "default": false,
                      "description": "If enabled, the authorization header or parameter can be overridden in the request by the value configured in the plugin.",
                      "required": false,
                      "type": "boolean"
                    }
                  },
                  {
                    "aws_access_key_id": {
                      "description": "Set this if you are using an AWS provider (Bedrock) and you are authenticating using static IAM User credentials. Setting this will override the AWS_ACCESS_KEY_ID environment variable for this plugin instance.",
                      "encrypted": true,
                      "referenceable": true,
                      "required": false,
                      "type": "string"
                    }
                  },
                  {
                    "aws_secret_access_key": {
                      "description": "Set this if you are using an AWS provider (Bedrock) and you are authenticating using static IAM User credentials. Setting this will override the AWS_SECRET_ACCESS_KEY environment variable for this plugin instance.",
                      "encrypted": true,
                      "referenceable": true,
                      "required": false,
                      "type": "string"
                    }
                  },
                  {
                    "azure_client_id": {
                      "description": "If azure_use_managed_identity is set to true, and you need to use a different user-assigned identity for this LLM instance, set the client ID.",
                      "referenceable": true,
                      "required": false,
                      "type": "string"
                    }
                  },
                  {
                    "azure_client_secret": {
                      "description": "If azure_use_managed_identity is set to true, and you need to use a different user-assigned identity for this LLM instance, set the client secret.",
                      "encrypted": true,
                      "referenceable": true,
                      "required": false,
                      "type": "string"
                    }
                  },
                  {
                    "azure_tenant_id": {
                      "description": "If azure_use_managed_identity is set to true, and you need to use a different user-assigned identity for this LLM instance, set the tenant ID.",
                      "referenceable": true,
                      "required": false,
                      "type": "string"
                    }
                  },
                  {
                    "azure_use_managed_identity": {
                      "default": false,
                      "description": "Set true to use the Azure Cloud Managed Identity (or user-assigned identity) to authenticate with Azure-provider models.",
                      "required": false,
                      "type": "boolean"
                    }
                  },
                  {
                    "gcp_service_account_json": {
                      "description": "Set this field to the full JSON of the GCP service account to authenticate, if required. If null (and gcp_use_service_account is true), Kong will attempt to read from environment variable `GCP_SERVICE_ACCOUNT`.",
                      "encrypted": true,
                      "referenceable": true,
                      "required": false,
                      "type": "string"
                    }
                  },
                  {
                    "gcp_use_service_account": {
                      "default": false,
                      "description": "Use service account auth for GCP-based providers and models.",
                      "required": false,
                      "type": "boolean"
                    }
                  },
                  {
                    "header_name": {
                      "description": "If AI model requires authentication via Authorization or API key header, specify its name here.",
                      "referenceable": true,
                      "required": false,
                      "type": "string"
                    }
                  },
                  {
                    "header_value": {
                      "description": "Specify the full auth header value for 'header_name', for example 'Bearer key' or just 'key'.",
                      "encrypted": true,
                      "referenceable": true,
                      "required": false,
                      "type": "string"
                    }
                  },
                  {
                    "param_location": {
                      "description": "Specify whether the 'param_name' and 'param_value' options go in a query string, or the POST form/JSON body.",
                      "one_of": [
                        "body",
                        "query"
                      ],
                      "required": false,
                      "type": "string"
                    }
                  },
                  {
                    "param_name": {
                      "description": "If AI model requires authentication via query parameter, specify its name here.",
                      "referenceable": true,
                      "required": false,
                      "type": "string"
                    }
                  },
                  {
                    "param_value": {
                      "description": "Specify the full parameter value for 'param_name'.",
                      "encrypted": true,
                      "referenceable": true,
                      "required": false,
                      "type": "string"
                    }
                  }
                ],
                "required": false,
                "type": "record"
              }
            },
            {
              "description": {
                "description": "The semantic description of the target, required if using semantic load balancing. Specially, setting this to 'CATCHALL' will indicate such target to be used when no other targets match the semantic threshold.",
                "required": false,
                "type": "string"
              }
            },
            {
              "logging": {
                "fields": [
                  {
                    "log_payloads": {
                      "default": false,
                      "description": "If enabled, will log the request and response body into the Kong log plugin(s) output.",
                      "required": true,
                      "type": "boolean"
                    }
                  },
                  {
                    "log_statistics": {
                      "default": false,
                      "description": "If enabled and supported by the driver, will add model usage and token metrics into the Kong log plugin(s) output.",
                      "required": true,
                      "type": "boolean"
                    }
                  }
                ],
                "required": true,
                "type": "record"
              }
            },
            {
              "model": {
                "fields": [
                  {
                    "name": {
                      "description": "Model name to execute.",
                      "required": false,
                      "type": "string"
                    }
                  },
                  {
                    "options": {
                      "description": "Key/value settings for the model",
                      "fields": [
                        {
                          "anthropic_version": {
                            "description": "Defines the schema/API version, if using Anthropic provider.",
                            "required": false,
                            "type": "string"
                          }
                        },
                        {
                          "azure_api_version": {
                            "default": "2023-05-15",
                            "description": "'api-version' for Azure OpenAI instances.",
                            "required": false,
                            "type": "string"
                          }
                        },
                        {
                          "azure_deployment_id": {
                            "description": "Deployment ID for Azure OpenAI instances.",
                            "required": false,
                            "type": "string"
                          }
                        },
                        {
                          "azure_instance": {
                            "description": "Instance name for Azure OpenAI hosted models.",
                            "required": false,
                            "type": "string"
                          }
                        },
                        {
                          "bedrock": {
                            "entity_checks": [
                              {
                                "mutually_required": [
                                  "aws_assume_role_arn",
                                  "aws_role_session_name"
                                ]
                              }
                            ],
                            "fields": [
                              {
                                "aws_assume_role_arn": {
                                  "description": "If using AWS providers (Bedrock) you can assume a different role after authentication with the current IAM context is successful.",
                                  "required": false,
                                  "type": "string"
                                }
                              },
                              {
                                "aws_region": {
                                  "description": "If using AWS providers (Bedrock) you can override the `AWS_REGION` environment variable by setting this option.",
                                  "required": false,
                                  "type": "string"
                                }
                              },
                              {
                                "aws_role_session_name": {
                                  "description": "If using AWS providers (Bedrock), set the identifier of the assumed role session.",
                                  "type": "string"
                                }
                              },
                              {
                                "aws_sts_endpoint_url": {
                                  "description": "If using AWS providers (Bedrock), override the STS endpoint URL when assuming a different role.",
                                  "type": "string"
                                }
                              },
                              {
                                "embeddings_normalize": {
                                  "default": false,
                                  "description": "If using AWS providers (Bedrock), set to true to normalize the embeddings.",
                                  "type": "boolean"
                                }
                              },
                              {
                                "performance_config_latency": {
                                  "description": "Force the client's performance configuration 'latency' for all requests. Leave empty to let the consumer select the performance configuration.",
                                  "required": false,
                                  "type": "string"
                                }
                              }
                            ],
                            "required": false,
                            "type": "record"
                          }
                        },
                        {
                          "cohere": {
                            "fields": [
                              {
                                "embedding_input_type": {
                                  "default": "classification",
                                  "description": "The purpose of the input text to calculate embedding vectors.",
                                  "one_of": [
                                    "classification",
                                    "clustering",
                                    "image",
                                    "search_document",
                                    "search_query"
                                  ],
                                  "required": false,
                                  "type": "string"
                                }
                              },
                              {
                                "wait_for_model": {
                                  "description": "Wait for the model if it is not ready",
                                  "required": false,
                                  "type": "boolean"
                                }
                              }
                            ],
                            "required": false,
                            "type": "record"
                          }
                        },
                        {
                          "embeddings_dimensions": {
                            "description": "If using embeddings models, set the number of dimensions to generate.",
                            "gt": 0,
                            "required": false,
                            "type": "integer"
                          }
                        },
                        {
                          "gemini": {
                            "entity_checks": [
                              {
                                "mutually_required": [
                                  "api_endpoint",
                                  "location_id",
                                  "project_id"
                                ]
                              }
                            ],
                            "fields": [
                              {
                                "api_endpoint": {
                                  "description": "If running Gemini on Vertex, specify the regional API endpoint (hostname only).",
                                  "required": false,
                                  "type": "string"
                                }
                              },
                              {
                                "location_id": {
                                  "description": "If running Gemini on Vertex, specify the location ID.",
                                  "required": false,
                                  "type": "string"
                                }
                              },
                              {
                                "project_id": {
                                  "description": "If running Gemini on Vertex, specify the project ID.",
                                  "required": false,
                                  "type": "string"
                                }
                              }
                            ],
                            "required": false,
                            "type": "record"
                          }
                        },
                        {
                          "huggingface": {
                            "fields": [
                              {
                                "use_cache": {
                                  "description": "Use the cache layer on the inference API",
                                  "required": false,
                                  "type": "boolean"
                                }
                              },
                              {
                                "wait_for_model": {
                                  "description": "Wait for the model if it is not ready",
                                  "required": false,
                                  "type": "boolean"
                                }
                              }
                            ],
                            "required": false,
                            "type": "record"
                          }
                        },
                        {
                          "input_cost": {
                            "description": "Defines the cost per 1M tokens in your prompt.",
                            "gt": 0,
                            "required": false,
                            "type": "number"
                          }
                        },
                        {
                          "llama2_format": {
                            "description": "If using llama2 provider, select the upstream message format.",
                            "one_of": [
                              "ollama",
                              "openai",
                              "raw"
                            ],
                            "required": false,
                            "type": "string"
                          }
                        },
                        {
                          "max_tokens": {
                            "description": "Defines the max_tokens, if using chat or completion models.",
                            "required": false,
                            "type": "integer"
                          }
                        },
                        {
                          "mistral_format": {
                            "description": "If using mistral provider, select the upstream message format.",
                            "one_of": [
                              "ollama",
                              "openai"
                            ],
                            "required": false,
                            "type": "string"
                          }
                        },
                        {
                          "output_cost": {
                            "description": "Defines the cost per 1M tokens in the output of the AI.",
                            "gt": 0,
                            "required": false,
                            "type": "number"
                          }
                        },
                        {
                          "temperature": {
                            "between": [
                              0,
                              5
                            ],
                            "description": "Defines the matching temperature, if using chat or completion models.",
                            "required": false,
                            "type": "number"
                          }
                        },
                        {
                          "top_k": {
                            "between": [
                              0,
                              500
                            ],
                            "description": "Defines the top-k most likely tokens, if supported.",
                            "required": false,
                            "type": "integer"
                          }
                        },
                        {
                          "top_p": {
                            "between": [
                              0,
                              1
                            ],
                            "description": "Defines the top-p probability mass, if supported.",
                            "required": false,
                            "type": "number"
                          }
                        },
                        {
                          "upstream_path": {
                            "deprecation": {
                              "message": "llm: config.model.options.upstream_path is deprecated, please use config.model.options.upstream_url instead",
                              "removal_in_version": "4.0"
                            },
                            "description": "Manually specify or override the AI operation path, used when e.g. using the 'preserve' route_type.",
                            "required": false,
                            "type": "string"
                          }
                        },
                        {
                          "upstream_url": {
                            "description": "Manually specify or override the full URL to the AI operation endpoints, when calling (self-)hosted models, or for running via a private endpoint.",
                            "required": false,
                            "type": "string"
                          }
                        }
                      ],
                      "required": false,
                      "type": "record"
                    }
                  },
                  {
                    "provider": {
                      "description": "AI provider request format - Kong translates requests to and from the specified backend compatible formats.",
                      "one_of": [
                        "anthropic",
                        "azure",
                        "bedrock",
                        "cohere",
                        "gemini",
                        "huggingface",
                        "llama2",
                        "mistral",
                        "openai"
                      ],
                      "required": true,
                      "type": "string"
                    }
                  }
                ],
                "required": true,
                "type": "record"
              }
            },
            {
              "route_type": {
                "description": "The model's operation implementation, for this provider. ",
                "one_of": [
                  "audio/v1/audio/speech",
                  "audio/v1/audio/transcriptions",
                  "audio/v1/audio/translations",
                  "image/v1/images/edits",
                  "image/v1/images/generations",
                  "llm/v1/assistants",
                  "llm/v1/batches",
                  "llm/v1/chat",
                  "llm/v1/completions",
                  "llm/v1/embeddings",
                  "llm/v1/files",
                  "llm/v1/responses",
                  "preserve",
                  "realtime/v1/realtime"
                ],
                "required": true,
                "type": "string"
              }
            },
            {
              "weight": {
                "between": [
                  1,
                  65535
                ],
                "default": 100,
                "description": "The weight this target gets within the upstream loadbalancer (1-65535).",
                "type": "integer"
              }
            }
          ],
          "required": "SKIPPED",
          "type": "record"
        },
        "required": true,
        "type": "array"
      }
    },
    {
      "vectordb": {
        "fields": [
          {
            "dimensions": {
              "description": "the desired dimensionality for the vectors",
              "required": true,
              "type": "integer"
            }
          },
          {
            "distance_metric": {
              "description": "the distance metric to use for vector searches",
              "one_of": [
                "cosine",
                "euclidean"
              ],
              "required": true,
              "type": "string"
            }
          },
          {
            "pgvector": {
              "fields": [
                {
                  "database": {
                    "default": "kong-pgvector",
                    "description": "the database of the pgvector database",
                    "type": "string"
                  }
                },
                {
                  "host": {
                    "default": "127.0.0.1",
                    "description": "the host of the pgvector database",
                    "type": "string"
                  }
                },
                {
                  "password": {
                    "description": "the password of the pgvector database",
                    "encrypted": true,
                    "referenceable": true,
                    "type": "string"
                  }
                },
                {
                  "port": {
                    "default": 5432,
                    "description": "the port of the pgvector database",
                    "type": "integer"
                  }
                },
                {
                  "ssl": {
                    "default": false,
                    "description": "whether to use ssl for the pgvector database",
                    "type": "boolean"
                  }
                },
                {
                  "ssl_cert": {
                    "description": "the path of ssl cert to use for the pgvector database",
                    "type": "string"
                  }
                },
                {
                  "ssl_cert_key": {
                    "description": "the path of ssl cert key to use for the pgvector database",
                    "type": "string"
                  }
                },
                {
                  "ssl_required": {
                    "default": false,
                    "description": "whether ssl is required for the pgvector database",
                    "type": "boolean"
                  }
                },
                {
                  "ssl_verify": {
                    "default": false,
                    "description": "whether to verify ssl for the pgvector database",
                    "type": "boolean"
                  }
                },
                {
                  "ssl_version": {
                    "default": "tlsv1_2",
                    "description": "the ssl version to use for the pgvector database",
                    "one_of": [
                      "any",
                      "tlsv1_2",
                      "tlsv1_3"
                    ],
                    "type": "string"
                  }
                },
                {
                  "timeout": {
                    "default": 5000,
                    "description": "the timeout of the pgvector database",
                    "type": "number"
                  }
                },
                {
                  "user": {
                    "default": "postgres",
                    "description": "the user of the pgvector database",
                    "referenceable": true,
                    "type": "string"
                  }
                }
              ],
              "required": true,
              "type": "record"
            }
          },
          {
            "redis": {
              "entity_checks": [
                {
                  "conditional": {
                    "if_field": "connection_is_proxied",
                    "if_match": {
                      "eq": true
                    },
                    "then_field": "host",
                    "then_match": {
                      "required": true
                    }
                  }
                },
                {
                  "custom_entity_check": {
                    "field_sources": [
                      "connection_is_proxied",
                      "database"
                    ],
                    "run_with_missing_fields": true
                  }
                },
                {
                  "custom_entity_check": {
                    "field_sources": [
                      "cluster_nodes",
                      "connection_is_proxied"
                    ],
                    "run_with_missing_fields": true
                  }
                },
                {
                  "custom_entity_check": {
                    "field_sources": [
                      "connection_is_proxied",
                      "sentinel_role"
                    ],
                    "run_with_missing_fields": true
                  }
                },
                {
                  "mutually_required": [
                    "host",
                    "port"
                  ]
                },
                {
                  "mutually_required": [
                    "sentinel_master",
                    "sentinel_nodes",
                    "sentinel_role"
                  ]
                },
                {
                  "mutually_required": [
                    "connect_timeout",
                    "read_timeout",
                    "send_timeout"
                  ]
                }
              ],
              "fields": [
                {
                  "cluster_max_redirections": {
                    "default": 5,
                    "description": "Maximum retry attempts for redirection.",
                    "required": false,
                    "type": "integer"
                  }
                },
                {
                  "cluster_nodes": {
                    "description": "Cluster addresses to use for Redis connections when the `redis` strategy is defined. Defining this field implies using a Redis Cluster. The minimum length of the array is 1 element.",
                    "elements": {
                      "fields": [
                        {
                          "ip": {
                            "default": "127.0.0.1",
                            "description": "A string representing a host name, such as example.com.",
                            "required": true,
                            "type": "string"
                          }
                        },
                        {
                          "port": {
                            "between": [
                              0,
                              65535
                            ],
                            "default": 6379,
                            "description": "An integer representing a port number between 0 and 65535, inclusive.",
                            "type": "integer"
                          }
                        }
                      ],
                      "type": "record"
                    },
                    "len_min": 1,
                    "required": false,
                    "type": "array"
                  }
                },
                {
                  "connect_timeout": {
                    "between": [
                      0,
                      2147483646
                    ],
                    "default": 2000,
                    "description": "An integer representing a timeout in milliseconds. Must be between 0 and 2^31-2.",
                    "type": "integer"
                  }
                },
                {
                  "connection_is_proxied": {
                    "default": false,
                    "description": "If the connection to Redis is proxied (e.g. Envoy), set it `true`. Set the `host` and `port` to point to the proxy address.",
                    "required": false,
                    "type": "boolean"
                  }
                },
                {
                  "database": {
                    "default": 0,
                    "description": "Database to use for the Redis connection when using the `redis` strategy",
                    "type": "integer"
                  }
                },
                {
                  "host": {
                    "default": "127.0.0.1",
                    "description": "A string representing a host name, such as example.com.",
                    "type": "string"
                  }
                },
                {
                  "keepalive_backlog": {
                    "between": [
                      0,
                      2147483646
                    ],
                    "description": "Limits the total number of opened connections for a pool. If the connection pool is full, connection queues above the limit go into the backlog queue. If the backlog queue is full, subsequent connect operations fail and return `nil`. Queued operations (subject to set timeouts) resume once the number of connections in the pool is less than `keepalive_pool_size`. If latency is high or throughput is low, try increasing this value. Empirically, this value is larger than `keepalive_pool_size`.",
                    "type": "integer"
                  }
                },
                {
                  "keepalive_pool_size": {
                    "between": [
                      1,
                      2147483646
                    ],
                    "default": 256,
                    "description": "The size limit for every cosocket connection pool associated with every remote server, per worker process. If neither `keepalive_pool_size` nor `keepalive_backlog` is specified, no pool is created. If `keepalive_pool_size` isn't specified but `keepalive_backlog` is specified, then the pool uses the default value. Try to increase (e.g. 512) this value if latency is high or throughput is low.",
                    "type": "integer"
                  }
                },
                {
                  "password": {
                    "description": "Password to use for Redis connections. If undefined, no AUTH commands are sent to Redis.",
                    "encrypted": true,
                    "referenceable": true,
                    "type": "string"
                  }
                },
                {
                  "port": {
                    "between": [
                      0,
                      65535
                    ],
                    "default": 6379,
                    "description": "An integer representing a port number between 0 and 65535, inclusive.",
                    "type": "integer"
                  }
                },
                {
                  "read_timeout": {
                    "between": [
                      0,
                      2147483646
                    ],
                    "default": 2000,
                    "description": "An integer representing a timeout in milliseconds. Must be between 0 and 2^31-2.",
                    "type": "integer"
                  }
                },
                {
                  "send_timeout": {
                    "between": [
                      0,
                      2147483646
                    ],
                    "default": 2000,
                    "description": "An integer representing a timeout in milliseconds. Must be between 0 and 2^31-2.",
                    "type": "integer"
                  }
                },
                {
                  "sentinel_master": {
                    "description": "Sentinel master to use for Redis connections. Defining this value implies using Redis Sentinel.",
                    "type": "string"
                  }
                },
                {
                  "sentinel_nodes": {
                    "description": "Sentinel node addresses to use for Redis connections when the `redis` strategy is defined. Defining this field implies using a Redis Sentinel. The minimum length of the array is 1 element.",
                    "elements": {
                      "fields": [
                        {
                          "host": {
                            "default": "127.0.0.1",
                            "description": "A string representing a host name, such as example.com.",
                            "required": true,
                            "type": "string"
                          }
                        },
                        {
                          "port": {
                            "between": [
                              0,
                              65535
                            ],
                            "default": 6379,
                            "description": "An integer representing a port number between 0 and 65535, inclusive.",
                            "type": "integer"
                          }
                        }
                      ],
                      "type": "record"
                    },
                    "len_min": 1,
                    "required": false,
                    "type": "array"
                  }
                },
                {
                  "sentinel_password": {
                    "description": "Sentinel password to authenticate with a Redis Sentinel instance. If undefined, no AUTH commands are sent to Redis Sentinels.",
                    "encrypted": true,
                    "referenceable": true,
                    "type": "string"
                  }
                },
                {
                  "sentinel_role": {
                    "description": "Sentinel role to use for Redis connections when the `redis` strategy is defined. Defining this value implies using Redis Sentinel.",
                    "one_of": [
                      "any",
                      "master",
                      "slave"
                    ],
                    "type": "string"
                  }
                },
                {
                  "sentinel_username": {
                    "description": "Sentinel username to authenticate with a Redis Sentinel instance. If undefined, ACL authentication won't be performed. This requires Redis v6.2.0+.",
                    "referenceable": true,
                    "type": "string"
                  }
                },
                {
                  "server_name": {
                    "description": "A string representing an SNI (server name indication) value for TLS.",
                    "required": false,
                    "type": "string"
                  }
                },
                {
                  "ssl": {
                    "default": false,
                    "description": "If set to true, uses SSL to connect to Redis.",
                    "required": false,
                    "type": "boolean"
                  }
                },
                {
                  "ssl_verify": {
                    "default": false,
                    "description": "If set to true, verifies the validity of the server SSL certificate. If setting this parameter, also configure `lua_ssl_trusted_certificate` in `kong.conf` to specify the CA (or server) certificate used by your Redis server. You may also need to configure `lua_ssl_verify_depth` accordingly.",
                    "required": false,
                    "type": "boolean"
                  }
                },
                {
                  "username": {
                    "description": "Username to use for Redis connections. If undefined, ACL authentication won't be performed. This requires Redis v6.0.0+. To be compatible with Redis v5.x.y, you can set it to `default`.",
                    "referenceable": true,
                    "type": "string"
                  }
                }
              ],
              "required": true,
              "shorthand_fields": [
                {
                  "cluster_addresses": {
                    "deprecation": {
                      "message": "cluster_addresses is deprecated, please use cluster_nodes instead",
                      "removal_in_version": "4.0",
                      "replaced_with": [
                        {
                          "path": [
                            "cluster_nodes"
                          ]
                        }
                      ]
                    },
                    "elements": {
                      "type": "string"
                    },
                    "len_min": 1,
                    "type": "array"
                  }
                },
                {
                  "sentinel_addresses": {
                    "deprecation": {
                      "message": "sentinel_addresses is deprecated, please use sentinel_nodes instead",
                      "removal_in_version": "4.0",
                      "replaced_with": [
                        {
                          "path": [
                            "sentinel_nodes"
                          ]
                        }
                      ]
                    },
                    "elements": {
                      "type": "string"
                    },
                    "len_min": 1,
                    "type": "array"
                  }
                },
                {
                  "timeout": {
                    "deprecation": {
                      "message": "redis schema field `timeout` is deprecated, use `connect_timeout`, `send_timeout` and `read_timeout`",
                      "removal_in_version": "4.0",
                      "replaced_with": [
                        {
                          "path": [
                            "connect_timeout"
                          ]
                        },
                        {
                          "path": [
                            "send_timeout"
                          ]
                        },
                        {
                          "path": [
                            "read_timeout"
                          ]
                        }
                      ]
                    },
                    "type": "integer"
                  }
                }
              ],
              "type": "record"
            }
          },
          {
            "strategy": {
              "description": "which vector database driver to use",
              "one_of": [
                "pgvector",
                "redis"
              ],
              "required": true,
              "type": "string"
            }
          },
          {
            "threshold": {
              "description": "the default similarity threshold for accepting semantic search results (float)",
              "required": true,
              "type": "number"
            }
          }
        ],
        "required": false,
        "type": "record"
      }
    }
  ],
  "required": true,
  "type": "record"
}